{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SncSpvGm2VUS"
   },
   "source": [
    "# **Preparing Training Data for Land Cover Mapping**\n",
    "## Introduction\n",
    "Preparing training data for supervised land cover classification using satellite imagery such as Landsat and Sentinel-2 is crucial for accurate mapping, yet it presents several challenges.\n",
    "\n",
    "### Challenges in preparing training samples for supervised land cover\n",
    "- High-quality and consistent training data\n",
    "- Class imbalance\n",
    "- Mixed pixels\n",
    "- Temporal variations\n",
    "- Spectral confusion\n",
    "- Co-registration and geometric accuracy\n",
    "- Labor-intensive manual collection\n",
    "- Limited transferability\n",
    "\n",
    "### Check tutorial for preparing training data (polygons)\n",
    "- Watch Youtube video tutorial: https://www.youtube.com/watch?v=k--M1a-V_x4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoerQ1ama7Fh"
   },
   "source": [
    "## Initialize and authenticate Earth Engine\n",
    "To get started with Google Earth Engine (GEE), you need to initialize and authenticate the Earth Engine API. Follow these steps.\n",
    "\n",
    "\n",
    "First, import the Earth Engine API by importing the ee module into your Python environment. This module allows you to interact with the Earth Engine platform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "7a6_vlZcOZPU",
    "outputId": "14e86e8a-a292-471c-cd55-c2c4f3062417"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the API\n",
    "import ee\n",
    "\n",
    "# Import the geemap library\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V9idAmhc8X7"
   },
   "source": [
    "Next, initialize the Earth Engine API. You must initialize the API to use Earth Engine functionalities. This involves authenticating your session and initializing the library. When you run the ee.Initialize() command for the first time, you might be prompted to authenticate your session. This will open a web browser window where you need to log in with your Google account and grant Earth Engine access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "0hGRqMB4PN7N",
    "outputId": "44d17732-b5b2-4262-c854-c3c22252b198"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()\n",
    "\n",
    "# Initialize the library.\n",
    "ee.Initialize(project='ee-kamusoko-test') # Change to your EE project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rzLzHwHHyNe"
   },
   "source": [
    "## Import study area boundary\n",
    "First, import the study area boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ixeL13nmHreX",
    "outputId": "04a36434-0d14-4e74-a278-e5859de5f643"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the boundary\n",
    "boundary = ee.FeatureCollection('users/kamas72_ML_Zim_Cities/Bulawayo_Crop_Boundary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76K5l09OI7zm"
   },
   "source": [
    "## Import training data\n",
    "Next, we will import land cover training data (polygons), which was created in QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "wy3ft4D1JRu6",
    "outputId": "fae9705d-4b03-4b62-e1c4-64b9d69addb7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training polygons per land cover class (Cl_Id):\n",
      "Bare areas (Cl_Id=0): 154\n",
      "Built-up (Cl_Id=1): 806\n",
      "Cropland (Cl_Id=2): 169\n",
      "Grass / open areas (Cl_Id=3): 495\n",
      "Woodlands (Cl_Id=4): 335\n",
      "Water (Cl_Id=5): 19\n"
     ]
    }
   ],
   "source": [
    "# Load training datasets\n",
    "training_data = ee.FeatureCollection('users/kamas72_ML_Zim_Cities/Updated_TA_2020_Bul_May_21_GEE')\n",
    "\n",
    "# Get the histogram of classes (key = class value, value = count)\n",
    "histogram = training_data.aggregate_histogram('Cl_Id').getInfo()\n",
    "\n",
    "# Define a label map for clarity\n",
    "label_map = {\n",
    "    '0': \"Bare areas\",\n",
    "    '1': \"Built-up\",\n",
    "    '2': \"Cropland\",\n",
    "    '3': \"Grass / open areas\",\n",
    "    '4': \"Woodlands\",\n",
    "    '5': \"Water\"\n",
    "}\n",
    "\n",
    "print(\"Number of training polygons per land cover class (Cl_Id):\")\n",
    "for cl_id in sorted(histogram.keys(), key=int):\n",
    "    label = label_map.get(cl_id, f\"Class {cl_id}\")\n",
    "    print(f\"{label} (Cl_Id={cl_id}): {histogram[cl_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQtiCfzBjCBk"
   },
   "source": [
    "## Create Sentinel-2 composite\n",
    "The sentinel-2 mission offers a wide-swath, high-resolution, multispectral imaging capability with a global 5-day revisit frequency. The Sentinel-2 Multispectral Instrument (MSI) has 13 spectral bands, providing a comprehensive view of the Earth's surface. These bands are distributed as four at 10 meters, six at 20 meters, and three at 60 meters spatial resolution. For more detailed information about the Sentinel-2 mission, please visit https://sentinel.esa.int/web/sentinel/missions/sentinel-2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "YHrK17UDj542",
    "outputId": "b06fc23b-43c2-4e8a-e157-e413a0e3cd83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sentinel-2 SR data (Harmonized)\n",
    "s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "\n",
    "# Cloud masking function using SCL band\n",
    "def mask_s2clouds(image):\n",
    "    scl = image.select('SCL')\n",
    "    mask = scl.neq(8).And(scl.neq(9)).And(scl.neq(10)).And(scl.neq(11))\n",
    "    return image.updateMask(mask).divide(10000)\n",
    "\n",
    "# Filter and preprocess Sentinel-2 data\n",
    "S2 = (s2.filterBounds(boundary)\n",
    "      .filterDate('2024-03-01', '2024-06-30')\n",
    "      .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
    "      .map(mask_s2clouds)\n",
    "      .select(['B2','B3','B4','B5','B6','B7','B8','B11','B12']))\n",
    "\n",
    "# Bands to include in the classification\n",
    "bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12']\n",
    "\n",
    "# Create a median composite\n",
    "composite = S2.median().clip(boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEgM_Yg7r3nE"
   },
   "source": [
    "## Display training samples and Sentine-2\n",
    "Next, display the land cover training samples on Sentinel-2 imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621,
     "referenced_widgets": [
      "bc9a58655482448da75675a39d13b73e",
      "55a5a291f83a43bfbbf6c287b37ff209",
      "1cd7822f5bb4457e92712dc61f1cc169",
      "5eac73c798fb47c08e86718b4eb346be",
      "47050bad05184cca8a9e661e8bbea3ef",
      "5484f104c4d941e0877e0614f5f98413",
      "ec9f6cdd9aea4dc48121059ed2dc9f25",
      "3d3b25358ace4075a751fd0f3201ff25",
      "6b8de3a6f5db45658d88ee2772e74a2b",
      "4a25db32b3dc49aead9e061e1c7f6516",
      "722da50fba7c4be081db5eac3fa0913d",
      "d02378af7a75488ea49b348b648fb91b",
      "ea296b1aa1b2420093fb8635efc189ed",
      "cdda29e7691e42988c62080c1cff1584",
      "cd8148c616b34b8a9d679fa1edb8db8e",
      "32605937f4014e7cbb0dc4afcfdcc22d",
      "558e7c284caf4d82b04061a5e449746d",
      "e159f3b0d7a143298ea3085f85a0d7a8",
      "c9753517535247ad8f36851cf06da4e0",
      "912b1dc0a1ba41a8889f1765a1a08b7c",
      "5947c2b0bcfd41cfa534af6d3e57f318",
      "ba8460182c7543678b38132fcf49f33c",
      "0ebba7c6a3c34ea9bbcdb7d6efbb111d",
      "f0eaa7ec2d11424db6d980bc6e2ed57f",
      "9b1e3520b245483fb795e42dc7861c99",
      "b1478cd3c1d047ef95a005d83a9554c2",
      "45fdfbd01c714ae2bb0751ae28b93ee9",
      "9836690436ea4016a29cbb221a996e65",
      "be1d8b90090045118af3c8963f4be80c",
      "33fe3d2f449f4b9fba3b0248f7d68df2",
      "7eb83f2dc0c844a5836d594ee947ed5c",
      "6363901bbd544f938cb1aa63fa71bc41",
      "3b9d0490899245d9ba06de8e14814b7e",
      "2177d761ddd349aa8b79926b3bddf035",
      "f426060b7ac140c18e9a1a5b3396038f",
      "48d9d01dc0174565810c6c93ee0c21a8",
      "2c964ae02ba54f7a9eb61e368dafccd8",
      "8684638867024d71808cf4796f98dfcb",
      "9645ad4ed5a24282a8c02c8637ffff4e",
      "efa74596bb0a489aa90cbacb7d8c7cda",
      "048cf5c8118a4c53ba1863f28e7fbd90",
      "97a71efe89d34cc28b866289336203a9",
      "8946cf720546494c9c3baea9202f2068",
      "1f3b129c118c4e3eb7539b3404f508f7",
      "cdf839386a2a41239b1d2795e9aa7f95",
      "4d65fc4ecb694bcdb4c44976e8687dd7",
      "f351fc02ca9d4d7d9c278679d1869917",
      "7a98a194bec349558385dfc916b3f9da",
      "fb245a3397304594a796ac20a6b432aa",
      "4fbd66eb469a40eeb784331ad47846f2",
      "231f12765bc842d38a24fb8ed4202841",
      "5279cee3c5024e37aa664ccc8cf28dc0",
      "6ce973918c1a470aa21ff2ef9cbe447a",
      "19323dc095a247fea93863ee802ec13e",
      "653b576f2cc041b58478a2c6ab548291",
      "e43c791e146146aaa0fbd9e36ff3f1aa",
      "b64898d3b8e74ccdad046b396bd11c55",
      "3acff0e9f6bb4c50935f263e3cca1899",
      "7e721f1c4aa14eea8af137e2887bdb1c",
      "91967712d43848d39e5b0289732ab354",
      "51f7c7afd66a4fdf828751ed70344497",
      "37b7b6e36d5244b98d5bfaf5d824a8fa",
      "5a374e1ab34c45cfb64dfec9c3ee6f32",
      "e01419d27329437e81702ade6baf40b0",
      "d7935cd2eab94d9685d7f348af443a62",
      "491f55a064a646c4af655c10c0f1c51c",
      "54b468355b3a4ae8b527406b5fb32fc7",
      "24577e2d019440ac90b8a70936d2d146",
      "9ff1c509a60042eebec117f751cd92d0",
      "e907d05591ac4617bbc8a47ca5a68fbe",
      "5fbb7f666d0f4fd59f0716c880647b41",
      "5f9f8e1199364d208a6c76f53ea1a7d6",
      "6268950a72bd4afea1465ce80413aa81",
      "fa1055bae47b424d8406f71db81c076a",
      "6936a1ee062b4c588e997bc12b5ab489",
      "0120ae949c704d108bb75a2bb09a9a82",
      "ac26686b32fc48c8a3f97da381f51316",
      "af884f2c967d47629ceb89838d33b28f",
      "73f056f7a0704db99f0c8cff71b2db50",
      "810ac21d1cf3483c9a6616771ccdfbaf",
      "bd5977c26f8e4c4fab453cf3fc6bb3d6",
      "641207bb92964c9282f587ec9435796b",
      "6889f12a664c47dda11a0204f967b877",
      "d5c3402184f24c16a6af2a37a2ccb2d7",
      "564b4a2a9e7c4f06bc34f160b38c9587",
      "bcf31a14ee2b404cb56e492c9b276fbf",
      "9c78a757f01f42028d579155a99c05bc",
      "0559dd7387a94c85807e0b1d3a628555",
      "c907e8702e0949aa8f7c4fe9fb4678cf",
      "35ac44f3c90042afb3754b8e1c68c1bd",
      "a4a2d543562f4ae0a953cf6db40d8962"
     ]
    },
    "id": "L0jVI-EZoOYB",
    "outputId": "56316433-a9b9-490c-926a-ce0bce921477"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9a58655482448da75675a39d13b73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-20.071642895480387, 28.547525199943355], controls=(WidgetControl(options=['position', 'transparenâ€¦"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the map\n",
    "map = geemap.Map()\n",
    "map.centerObject(training_data, 12)\n",
    "\n",
    "# Add Sentinel-2 composite\n",
    "map.addLayer(composite, {'bands': ['B11', 'B8', 'B3'], 'min': 0, 'max': 0.3}, 'Sentinel-2 Composite')\n",
    "\n",
    "# Add training data as a layer\n",
    "map.addLayer(training_data, {'color': 'red'}, 'Training Data')\n",
    "\n",
    "# Display the map with layer control\n",
    "map.addLayerControl()\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUAu9jH49iyr"
   },
   "source": [
    "## Prepare training data\n",
    "In this step, we prepare the dataset for training and testing machine learning models by processing satellite imagery and training labels. We start by selecting Sentinel-2 bands (B2 to B12) and clipping the composite image to the specified boundary region, defining the input features. Next, we rasterize the vector training data using the Cl_Id property to create a raster layer representing class labels and add it as a new band (class) to the input features. To create a representative dataset, we use stratified sampling to extract reflectance values and class labels, ensuring proportional representation across classes. A random column is added to the dataset with a fixed seed for reproducibility, allowing us to split the data into 70% for training and 30% for validation. Finally, we confirm the dataset sizes to ensure the split is as intended. This process prepares the data for effective training and validation of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "dxvkaFEP9jp0",
    "outputId": "d234c870-aade-4da0-c2bb-d308ce5b8d13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input features:  {'type': 'Image', 'bands': [{'id': 'B2', 'data_type': {'type': 'PixelType', 'precision': 'float', 'min': 0, 'max': 6.553500175476074}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B3', 'data_type': {'type': 'PixelType', 'precision': 'float', 'min': 0, 'max': 6.553500175476074}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B4', 'data_type': {'type': 'PixelType', 'precision': 'float', 'min': 0, 'max': 6.553500175476074}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5', 'data_type': {'type': 'PixelType', 'precision': 'float', 'min': 0, 'max': 6.553500175476074}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B6', 'data_type': {'type': 'PixelType', 'precision': 'float', 'min': 0, 'max': 6.553500175476074}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B7', 'data_type': {'type': 'PixelType', 'precision': 'float', 'min': 0, 'max': 6.553500175476074}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B8', 'data_type': {'type': 'PixelType', 'precision': 'float', 'min': 0, 'max': 6.553500175476074}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B11', 'data_type': {'type': 'PixelType', 'precision': 'float', 'min': 0, 'max': 6.553500175476074}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B12', 'data_type': {'type': 'PixelType', 'precision': 'float', 'min': 0, 'max': 6.553500175476074}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n"
     ]
    }
   ],
   "source": [
    "# Use ee.List for band selection\n",
    "bands = ee.List(['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12'])\n",
    "input_features = composite.clip(boundary)\n",
    "print('input features: ', input_features.getInfo())\n",
    "\n",
    "# Rasterise training data\n",
    "training_rasterized = training_data.reduceToImage(\n",
    "    properties=['Cl_Id'],\n",
    "    reducer=ee.Reducer.first()\n",
    ").toInt().remap([0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]) # Bare areas, Built-up, Cropland, Grass/ open areas, Woodlands, Water\n",
    "\n",
    "# Add a class band to features\n",
    "input_features = input_features.addBands(training_rasterized.toInt().rename('class'))\n",
    "\n",
    "# Sample the reflectance, elevation, and slope values for each training point\n",
    "training_dataset = input_features.stratifiedSample(\n",
    "    numPoints=10000,\n",
    "    classBand=\"class\",\n",
    "    region=boundary,\n",
    "    scale=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPIPLBF45Ahj"
   },
   "source": [
    "## Export the training points\n",
    "We export the 'training_data' feature collection, Sentinel-2 composite and PALSAR ScanSAR images to your Google Drive. After configuring the export, the task is started with task.start()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "I5OQCrvJtSsF",
    "outputId": "3427b3d8-66ef-4b01-ff85-795433b64b00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Export training samples as CSV\n",
    "task_table = ee.batch.Export.table.toDrive(\n",
    "    collection=training_dataset,\n",
    "    description='Bul_TrainingData_2024',\n",
    "    folder='Bulawayo_Dataset_2024',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "# Start the export task\n",
    "task_table.start()\n",
    "\n",
    "# Export the composite with indices\n",
    "task_composite = ee.batch.Export.image.toDrive(\n",
    "    image=composite.float(),\n",
    "    description='Bul_S2_2024',\n",
    "    folder='Bulawayo_Dataset_2024',\n",
    "    scale=10,\n",
    "    region=boundary.geometry(),\n",
    "    maxPixels=1e13\n",
    ")\n",
    "task_composite.start()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
