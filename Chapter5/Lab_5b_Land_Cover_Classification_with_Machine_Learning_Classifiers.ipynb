{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 5b: Improving Land Cover Classification Using Optical and SAR Imagery**\n",
        "\n",
        "## Introduction\n",
        "This lab will use a random forest classifier to classify optical (Sentinel-2) and SAR (ALOS PALSAR ScanSAR HV polarization) images. The goal is to improve land cover classification by combining optical and SAR imagery."
      ],
      "metadata": {
        "id": "98VODWhEJzmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Setup\n",
        "### Install libraries\n",
        "First, install any additional libraries that are not installed by default (e.g., rasterio, earthpy).."
      ],
      "metadata": {
        "id": "-pwDPkalAvRb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWr5V6krNx-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa39753f-6c57-44b8-f366-b5fcbae298cc",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n",
            "Collecting earthpy\n",
            "  Downloading earthpy-0.9.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (from earthpy) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from earthpy) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from earthpy) (2.0.2)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (from earthpy) (1.4.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from earthpy) (0.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from earthpy) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (2.8.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (0.10.0)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (2.0.7)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->earthpy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->earthpy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->earthpy) (2.3.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (2025.3.13)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (0.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas->earthpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas->earthpy) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->earthpy) (1.17.0)\n",
            "Downloading earthpy-0.9.4-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: earthpy\n",
            "Successfully installed earthpy-0.9.4\n"
          ]
        }
      ],
      "source": [
        "# Install rasterio and earthpy libraries\n",
        "!pip install rasterio\n",
        "!pip install earthpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries\n",
        "Import the necessary libraries (pandas, numpy, scikit-learn, rasterio, etc.)."
      ],
      "metadata": {
        "id": "SIhoHLoHq8_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import earthpy.plot as ep\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import from_levels_and_colors\n",
        "import seaborn as sns\n",
        "import joblib"
      ],
      "metadata": {
        "id": "F6bfz1KZzA-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive\n",
        "Next, mount your Google Drive. You will be prompted to authorize access to your Google Drive. Once mounted, you can read/write files in /content/drive/MyDrive."
      ],
      "metadata": {
        "id": "bzVfa9mtzRMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXvi8JvIzRmY",
        "outputId": "4e3efa9c-19c7-48d5-9819-9b6d14e710dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define paths and variables\n",
        "Define the the paths to access your own directory structure in Google Drive. In this tutorial, we use:\n",
        "-A CSV training dataset (Bul_TrainingData_2024.csv) containing pixel values and their corresponding classes.\n",
        "- A multiband Sentinel-2 image (Bul_S2_2024.tif).\n",
        "- PALSAR ScanSAR polarization"
      ],
      "metadata": {
        "id": "l0HWzfHGzVCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path that contains the datasets\n",
        "Sample_Path = '/content/drive/MyDrive/Bulawayo_Dataset_2024/Bul_TA_S2_Pal_2024.csv'\n",
        "S2_Image_Path = '/content/drive/MyDrive/Bulawayo_Dataset_2024/Bul_S2_2024.tif'\n",
        "Palsar_Image_Path = '/content/drive/MyDrive/Bulawayo_Dataset_2024/Bul_Palsar_HV_2024.tif'"
      ],
      "metadata": {
        "id": "Vj2kFuhMzVd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define target and predictor variables\n",
        "Next, define and specify the overall structure of the land cover classification task. Bands lists the Sentinel-2 spectral bands (e.g., B2, B3, B4) used as input features (predictors) for the model, while LC indicates the target column named “class.” Classes is a list of integer codes that the model will learn to predict, and N_Classes denotes the total number of these categories. The Names list provides descriptive labels (e.g., “Bare area,” “Built-up”) that match each code, making it easier to interpret results. Finally, Palette is a set of hex color codes for visualizing each class in plots or exported maps."
      ],
      "metadata": {
        "id": "xaZUI5eOz8PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target and predictor variables\n",
        "Bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12', 'HV']  # Feature columns\n",
        "LC = ['class']\n",
        "\n",
        "Classes = [0, 1, 2, 3, 4, 5]\n",
        "N_Classes = 6\n",
        "Names   = [\"Bare area\", \"Built-up\", \"Cropland\", \"Grassland\", \"Woodland\", \"Water\"]\n",
        "Palette = [\n",
        "    '#D3D3D3',  # grey for class 0 (Bare area)\n",
        "    '#FF0000',  # red for class 1 (Built-up)\n",
        "    '#FFD700',  # gold for class 2 (Cropland)\n",
        "    '#ADFF2F',  # greenyellow for class 3 (Grassland)\n",
        "    '#006400',  # darkgreen for class 4 (Woodland)\n",
        "    '#0000FF'   # blue for class 5 (Water)\n",
        "]"
      ],
      "metadata": {
        "id": "WjFAe4hjM2VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Images\n",
        "We will use rasterio to open the .tif file. These are Sentinel-2 imagery and ALOS PALSAR ScanSAR HV polarization."
      ],
      "metadata": {
        "id": "GVQZaVjI3lT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Sentinel-2 image\n",
        "with rasterio.open(S2_Image_Path) as src_s2:\n",
        "    s2_array = src_s2.read()  # shape: [bands, height, width]\n",
        "    profile = src_s2.profile\n",
        "    height, width = src_s2.height, src_s2.width\n",
        "\n",
        "# Load PALSAR HV image\n",
        "with rasterio.open(Palsar_Image_Path) as src_palsar:\n",
        "    palsar_array = src_palsar.read(1)  # HV is single-band: [height, width]\n",
        "\n",
        "# Ensure shapes match\n",
        "assert s2_array.shape[1:] == palsar_array.shape, \"Image sizes don't match. Reproject or resample needed.\""
      ],
      "metadata": {
        "id": "9l9ogzuvbsSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display images\n",
        "Display the Sentinel-2 composite and the PALSAR ScanSAR HV polorization image."
      ],
      "metadata": {
        "id": "2YkbgnVoeWJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select bands for RGB composite: B4 (Red), B3 (Green), B2 (Blue)\n",
        "# Note: Check your band ordering if uncertain\n",
        "red = s2_array[2, :, :]  # B4\n",
        "green = s2_array[1, :, :]  # B3\n",
        "blue = s2_array[0, :, :]  # B2\n",
        "\n",
        "# Stack and normalize for RGB display\n",
        "rgb = np.stack([red, green, blue], axis=-1)\n",
        "rgb_min, rgb_max = 0, 0.3  # Adjust depending on your scaling\n",
        "rgb_display = np.clip((rgb - rgb_min) / (rgb_max - rgb_min), 0, 1)\n",
        "\n",
        "# Normalized HV (grayscale display)\n",
        "hv_min, hv_max = 0,1\n",
        "hv_display = np.clip((palsar_array - hv_min) / (hv_max - hv_min), 0, 1)\n",
        "\n",
        "# Plot side by side\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 7))\n",
        "\n",
        "axs[0].imshow(rgb_display)\n",
        "axs[0].set_title('Sentinel-2 RGB (B4, B3, B2)')\n",
        "axs[0].axis('off')\n",
        "\n",
        "axs[1].imshow(hv_display, cmap='gray')\n",
        "axs[1].set_title('PALSAR HV Backscatter')\n",
        "axs[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xi6_Mmgvel1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Load and Prepare Training Data\n",
        "Next, load and prepare the training data. The training data is in a CSV format with columns for each band (B2, B3, etc.) and a class column (land cover type)."
      ],
      "metadata": {
        "id": "ZmtsZJvI3q4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data as a DataFrame\n",
        "df = pd.read_csv(Sample_Path)\n",
        "\n",
        "# Inspect first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Separate features (X) and label (y)\n",
        "X = df[Bands]\n",
        "y = df['class']\n",
        "\n",
        "# Ensure no missing values\n",
        "print(f\"Missing values in features: {X.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in label: {y.isnull().sum()}\")\n",
        "\n",
        "# Split into training and testing subsets\n",
        "# (you can also do cross-validation if you prefer)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}\")\n",
        "print(f\"Testing samples: {X_test.shape[0]}\")"
      ],
      "metadata": {
        "id": "TcAThBNC3rQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate Multiple Classifiers\n",
        "\n",
        "We will train four classifiers: K-nearest neighbors (KNN), support vector machine (SVM), decision tree, and random forest. Then we will compare their performance using accuracy, confusion matrices, and classification reports."
      ],
      "metadata": {
        "id": "X-8ljFQc-x2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_preds = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "ftWuB56n-ySm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model validation\n",
        "We will compare their performance using accuracy, confusion matrices, and classification reports."
      ],
      "metadata": {
        "id": "LSEEsDM_CyJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate each model\n",
        "models = {\n",
        "    \"Random Forest\": rf_preds\n",
        "}\n",
        "\n",
        "for name, preds in models.items():\n",
        "    print(f\"\\n** {name} **\")\n",
        "    print(\"Accuracy:\", (preds == y_test).mean())\n",
        "\n",
        "    # Classification Report\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, preds, labels=Classes)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Classes)\n",
        "    disp.plot(cmap='Blues')\n",
        "    plt.title(f\"{name} - Confusion Matrix\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7h4sLGwuC0Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Best RF Model\n",
        "Let's save the best RF model parameters, feature names, or other metadata together.\n"
      ],
      "metadata": {
        "id": "MdjQxy9Ref_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model parameters\n",
        "model_package = {\n",
        "    \"model\": rf,            # your trained Random Forest model\n",
        "    \"features\": Bands,      # input feature names\n",
        "    \"label\": 'class'        # label column name\n",
        "}\n",
        "\n",
        "# Define model path\n",
        "MODEL_PATH = '/content/drive/MyDrive/Bulawayo_Dataset_2024/best_rf_model.pkl'\n",
        "joblib.dump(model_package, MODEL_PATH)\n",
        "print(\"Model saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pe8OLc4egqh",
        "outputId": "a1045aa6-8bdf-4957-823c-dd5c873fd11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Land Cover Classification\n",
        "\n",
        "Choose one or more of the trained classifiers (e.g., Random Forest for demonstration) to predict class labels for every pixel of the Sentinel-2 image.\n",
        "\n",
        "### i. Stack Sentinel-2 and PALSAR HV images"
      ],
      "metadata": {
        "id": "IFpqICff_ak-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack PALSAR HV as an extra band ---\n",
        "palsar_array_expanded = palsar_array[np.newaxis, :, :]  # shape: [1, height, width]\n",
        "combined_array = np.concatenate((s2_array, palsar_array_expanded), axis=0)  # shape: [bands+1, height, width]\n",
        "print(\"Combined array shape:\", combined_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAFvKpb9YMYl",
        "outputId": "06617f23-92e9-4e79-b28b-b7d4796a6d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined array shape: (10, 4469, 5317)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ii. Reshape for prediction\n",
        "Scikit-Learn expects a 2D array for prediction, where each row corresponds to a pixel and each column corresponds to a band. Therefore, we need to reshape from (bands, height, width) to (height*width, bands) for input into Scikit-Learn."
      ],
      "metadata": {
        "id": "AlL8ULA-_luW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape for classification ---\n",
        "band_count = combined_array.shape[0]\n",
        "img_reshaped = combined_array.reshape(band_count, -1).T  # shape: [n_pixels, n_features]\n",
        "print(\"Reshaped array for prediction:\", img_reshaped.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPlHdUXoALMd",
        "outputId": "a25c0caf-5b3d-4706-a971-b0d0fe3701ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped array for prediction: (23761673, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iii.  Use the random forest for prediction\n",
        "Next, we will use the random forest for prediction. Finally, we will take a 1D array of predicted land cover classes and reshape it back into a 2D raster format (image) so it matches the original image's spatial dimensions."
      ],
      "metadata": {
        "id": "uyBBaiuWAOHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using trained RandomForest model (e.g. rf) ---\n",
        "prediction = rf.predict(img_reshaped)\n",
        "prediction = prediction.astype(np.uint8)\n",
        "\n",
        "# Reshape back to image\n",
        "prediction_map = prediction.reshape(height, width)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvDw97oDAYwJ",
        "outputId": "42e982b7-9679-4949-c007-6eccc3f3e249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the land cover map\n",
        "\n",
        "Next, visualize the resulting map with a color palette corresponding to each class ID."
      ],
      "metadata": {
        "id": "vxzKWUBiAcDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a discrete colormap\n",
        "# We need one more level than classes for from_levels_and_colors\n",
        "levels = Classes + [max(Classes) + 1]\n",
        "cmap, norm = from_levels_and_colors(levels, Palette)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "im = plt.imshow(prediction_map, cmap=cmap, norm=norm)\n",
        "plt.title(\"Land Cover Map\")\n",
        "\n",
        "# Create colorbar with a shrink factor (0.7 = 70% of default height)\n",
        "cbar = plt.colorbar(im, shrink=0.7)\n",
        "\n",
        "# Center tick labels\n",
        "tick_positions = [i + 0.5 for i in Classes]\n",
        "cbar.set_ticks(tick_positions)\n",
        "cbar.set_ticklabels(Names)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yLT-BbhQAkzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export the Land Cover Map\n",
        "We can save the land cover map to a new GeoTIFF using rasterio."
      ],
      "metadata": {
        "id": "Aft_fLsTAoUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predicted land cover map\n",
        "output_path = '/content/drive/MyDrive/Bulawayo_Dataset_2024/Bul_LC_RF_2024b.tif'\n",
        "with rasterio.open(\n",
        "    output_path, 'w',\n",
        "    driver='GTiff',\n",
        "    height=height,\n",
        "    width=width,\n",
        "    count=1,\n",
        "    dtype=np.uint8,\n",
        "    crs=profile['crs'],\n",
        "    transform=profile['transform']\n",
        ") as dst:\n",
        "    dst.write(prediction_map, 1)"
      ],
      "metadata": {
        "id": "sSzD142Gji8V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}