{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 5: Land Cover Classification Using Machine Learning: An Introductory Guide with Scikit-Learn**\n",
        "\n",
        "## Introduction\n",
        "This lab introduces participants to the application of machine learning algorithms for land cover classification using satellite imagery. Land cover classification is a fundamental task in remote sensing, supporting a wide range of applications including environmental monitoring, urban planning, agriculture, and natural resource management.\n",
        "\n",
        "In this lab, we explore and compare the performance of four commonly used machine learning classifiers k-nearest neighbor (KNN), support vector machines, decision trees, and random forest classifiers. These classifiers are implemented using the Scikit-Learn library in a Google Colab environment, making the lab accessible and easy to follow without requiring local software installations. Participants will learn how to load training and testing data, preprocess features, train different models, assess their performance using accuracy metrics, and visualize classification results.\n",
        "\n",
        "### Why use Scikit-Learn and Google Colab?\n",
        "- Scikit-Learn provides a user-friendly API for a variety of machine learning algorithms (e.g., Decision Trees, Random Forests, SVM, KNN, etc.).\n",
        "- Google Colab gives you free access to a remote environment with preinstalled libraries, GPU/TPU access, and easy integration with Google Drive.\n",
        "\n",
        "### Goal\n",
        "By the end of this lab, participants will have a foundational understanding of how to apply and evaluate basic machine learning algorithms for classifying land cover types from Earth observation data.\n"
      ],
      "metadata": {
        "id": "9enVF7go_Y6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Setup\n",
        "### Install libraries\n",
        "First, install any additional libraries that are not installed by default (e.g., rasterio, earthpy).."
      ],
      "metadata": {
        "id": "-pwDPkalAvRb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWr5V6krNx-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22446ea8-256b-40dc-ca97-7c266558dc94",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.1)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n",
            "Collecting earthpy\n",
            "  Downloading earthpy-0.9.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (from earthpy) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from earthpy) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from earthpy) (2.0.2)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (from earthpy) (1.4.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from earthpy) (0.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from earthpy) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (2.8.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (0.10.0)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (2.0.7)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->earthpy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->earthpy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->earthpy) (2.3.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (2025.3.13)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (0.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas->earthpy) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas->earthpy) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->earthpy) (1.17.0)\n",
            "Downloading earthpy-0.9.4-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: earthpy\n",
            "Successfully installed earthpy-0.9.4\n"
          ]
        }
      ],
      "source": [
        "# Install some packages\n",
        "!pip install rasterio\n",
        "!pip install earthpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries\n",
        "Import the necessary libraries (pandas, numpy, scikit-learn, rasterio, etc.)."
      ],
      "metadata": {
        "id": "SIhoHLoHq8_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import earthpy.plot as ep\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import from_levels_and_colors\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "F6bfz1KZzA-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive\n",
        "Next, mount your Google Drive. You will be prompted to authorize access to your Google Drive. Once mounted, you can read/write files in /content/drive/MyDrive."
      ],
      "metadata": {
        "id": "bzVfa9mtzRMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXvi8JvIzRmY",
        "outputId": "ce9a3568-95cf-4ea6-e27c-fccb2b17e18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define paths and variables\n",
        "Define the the paths to access your own directory structure in Google Drive. In this tutorial, we use:\n",
        "-A CSV training dataset (Bul_TrainingData_2024.csv) containing pixel values and their corresponding classes.\n",
        "- A multiband Sentinel-2 image (Bul_S2_2024.tif)."
      ],
      "metadata": {
        "id": "l0HWzfHGzVCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path that contains the datasets\n",
        "Sample_Path = '/content/drive/MyDrive/Bulawayo_Dataset_2024/Bul_TrainingData_2024.csv'\n",
        "Image_Path = '/content/drive/MyDrive/Bulawayo_Dataset_2024/Bul_S2_2024.tif'"
      ],
      "metadata": {
        "id": "Vj2kFuhMzVd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define target and predictor variables\n",
        "Next, define and specify the overall structure of the land cover classification task. Bands lists the Sentinel-2 spectral bands (e.g., B2, B3, B4) used as input features (predictors) for the model, while LC indicates the target column named “class.” Classes is a list of integer codes that the model will learn to predict, and N_Classes denotes the total number of these categories. The Names list provides descriptive labels (e.g., “Bare area,” “Built-up”) that match each code, making it easier to interpret results. Finally, Palette is a set of hex color codes for visualizing each class in plots or exported maps."
      ],
      "metadata": {
        "id": "xaZUI5eOz8PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target and predictor variables\n",
        "Bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12']  # Feature columns\n",
        "LC = ['class']\n",
        "\n",
        "Classes = [0, 1, 2, 3, 4, 5]\n",
        "N_Classes = 6\n",
        "Names   = [\"Bare area\", \"Built-up\", \"Cropland\", \"Grassland\", \"Woodland\", \"Water\"]\n",
        "Palette = [\n",
        "    '#D3D3D3',  # grey for class 0 (Bare area)\n",
        "    '#FF0000',  # red for class 1 (Built-up)\n",
        "    '#FFD700',  # gold for class 2 (Cropland)\n",
        "    '#ADFF2F',  # greenyellow for class 3 (Grassland)\n",
        "    '#006400',  # darkgreen for class 4 (Woodland)\n",
        "    '#0000FF'   # blue for class 5 (Water)\n",
        "]"
      ],
      "metadata": {
        "id": "WjFAe4hjM2VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Sentinel-2 Imagery\n",
        "We will use rasterio to open the .tif file. Sentinel-2 imagery often has multiple bands (e.g., 13 bands). In this guide, we will specifically use the bands listed in our Bands variable (B2, B3, B4, etc.)."
      ],
      "metadata": {
        "id": "GVQZaVjI3lT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the multiband Sentinel-2 image\n",
        "image = rasterio.open(Image_Path)\n",
        "\n",
        "band_count = image.count\n",
        "height = image.height\n",
        "width = image.width\n",
        "crs = image.crs\n",
        "transform = image.transform\n",
        "\n",
        "print(f\"Image has {band_count} bands.\")\n",
        "print(f\"Image dimensions: {height} rows x {width} columns\")\n",
        "print(f\"Coordinate Reference System (CRS): {crs}\")\n",
        "\n",
        "# For quick visualization (RGB = bands 4, 3, 2 if the image bands are in order)\n",
        "# If your image bands are in the order B2=1, B3=2, B4=3, ... B12=9,\n",
        "# then B4 is band index 3 in a 1-based system, so read(3):\n",
        "# Adjust these indices if necessary\n",
        "image_vis = []\n",
        "for b in [4, 3, 2]:  # Using B4, B3, B2 for a true color composite\n",
        "    image_vis.append(image.read(b))\n",
        "image_vis = np.stack(image_vis)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "ep.plot_rgb(\n",
        "    image_vis,\n",
        "    stretch=True\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HoHqzHWu3lwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Load and Prepare Training Data\n",
        "Next, load and prepare the training data. The training data is in a CSV format with columns for each band (B2, B3, etc.) and a class column (land cover type)."
      ],
      "metadata": {
        "id": "ZmtsZJvI3q4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data as a DataFrame\n",
        "df = pd.read_csv(Sample_Path)\n",
        "\n",
        "# Inspect first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Separate features (X) and label (y)\n",
        "X = df[Bands]\n",
        "y = df['class']\n",
        "\n",
        "# Ensure no missing values\n",
        "print(f\"Missing values in features: {X.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in label: {y.isnull().sum()}\")\n",
        "\n",
        "# Split into training and testing subsets\n",
        "# (you can also do cross-validation if you prefer)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}\")\n",
        "print(f\"Testing samples: {X_test.shape[0]}\")"
      ],
      "metadata": {
        "id": "TcAThBNC3rQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "Exploratory data analysis (EDA) is a critical initial step in the geospatial machine learning workflow. It involves the use of statistical summaries, visualizations, and spatial analysis techniques to gain insights into the structure, quality, and patterns present in the dataset before applying any classification algorithm.\n",
        "\n",
        "### Class distribution\n",
        "First, create a count plot of 'class' to show the distribution of training samples for each land cover class. EDA helps assess the balance of land cover classes (e.g., forest, water, urban, agriculture) within the dataset. Imbalanced class distributions can negatively affect model performance, especially in classification tasks."
      ],
      "metadata": {
        "id": "3vkhoIXFENZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine X_train with y_train for easy plotting\n",
        "df_train = X_train.copy()\n",
        "df_train['class'] = y_train.values\n",
        "\n",
        "# Set up the figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a count plot of 'class' to show the distribution of training samples for each class\n",
        "sns.countplot(\n",
        "    x='class',        # The column on the x-axis\n",
        "    data=df_train,    # The DataFrame containing our features and labels\n",
        "    palette=Palette   # Use the predefined color palette for each class\n",
        ")\n",
        "\n",
        "# Add a title to the plot\n",
        "plt.title('Distribution of Samples Across Classes')\n",
        "\n",
        "# Label the x-axis\n",
        "plt.xlabel('Class')\n",
        "\n",
        "# Label the y-axis\n",
        "plt.ylabel('Number of Samples')\n",
        "\n",
        "# Customize the x-ticks to show class names instead of numbers\n",
        "plt.xticks(\n",
        "    ticks=[0, 1, 2, 3, 4, 5],                           # Positions for each class\n",
        "    labels=['Bare area', 'Built-up', 'Cropland',        # Human-readable class names\n",
        "            'Grassland', 'Woodland', 'Water']\n",
        ")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QSI3CWuSIU5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scatter plot\n",
        "Next, create a scatter plot using the seaborn library. By analyzing how predictor variables (e.g., spectral bands) relate to each other and to the land cover classes, we can identify useful features for classification."
      ],
      "metadata": {
        "id": "mI5LkZJIEQj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine X_train with y_train for easy plotting\n",
        "df_train = X_train.copy()\n",
        "df_train['class'] = y_train.values\n",
        "\n",
        "# Scatter plot of B4 vs B8, colored by 'class'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(\n",
        "    x='B4',\n",
        "    y='B8',\n",
        "    hue='class',\n",
        "    data=df_train,\n",
        "    palette=Palette\n",
        ")\n",
        "plt.title('Scatter Plot of Band B4 vs. Band B8')\n",
        "plt.xlabel('Red (B4) reflectance')\n",
        "plt.ylabel('NIR (B8) reflectance')\n",
        "plt.legend(title='Class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sXV0pbQs2tTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pairwise scatter plots\n",
        "Next, we create pairwise scatter plots to visualize how each pair of spectral bands (e.g., B2 vs. B3, B2 vs. B4, etc.) relates to one another across the different classes. This helps us spot patterns, cluster tendencies, or any obvious band relationships, and it allows us to see if certain classes are well-separated (or highly overlapping) when viewed in different band combinations. Essentially, it’s a quick way to explore the distribution and separability of classes in a multi-dimensional feature space."
      ],
      "metadata": {
        "id": "p1vvGqlD3aEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the pairplot\n",
        "g = sns.pairplot(df_train, vars=Bands, hue='class', palette=Palette)\n",
        "\n",
        "# Add a main title (pairplot returns a PairGrid object, so we need g.fig)\n",
        "g.fig.suptitle('Pairwise Scatter Plots for All Bands', y=1.02)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EIxNI4gVERNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3D scatter plots\n",
        "Next, let's create a 3D scatter plot for the Sentinel-2 Blue (B2), Red (B4), and Near-Infrared (B8) bands using matplotlib. A 3D plot allows you to visualize the relationships among three different bands (e.g., Blue, Red, and Near Infrared) simultaneously, rather than just two at a time. This can reveal additional patterns or cluster separations in the feature space—for instance, whether certain classes become more distinguishable when you add a third dimension. It’s simply a more in-depth way to explore how your classes are distributed across multiple bands and can help you quickly spot any interesting trends or outliers."
      ],
      "metadata": {
        "id": "DuAFaLYiEZsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries needed\n",
        "from mpl_toolkits.mplot3d import Axes3D  # needed for 3D projections\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "# Create a color map from class labels to colors in the palette\n",
        "color_map = {class_label: Palette[i] for i, class_label in enumerate(Classes)}\n",
        "\n",
        "# Map each sample's class label to its corresponding color\n",
        "colors = df_train['class'].map(color_map)\n",
        "\n",
        "# Initialize the figure and 3D axis\n",
        "fig = plt.figure(figsize=(12, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Scatter plot:\n",
        "#   x-axis => B2 (Blue)\n",
        "#   y-axis => B4 (Red)\n",
        "#   z-axis => B8 (NIR)\n",
        "scatter = ax.scatter(\n",
        "    df_train['B2'],\n",
        "    df_train['B4'],\n",
        "    df_train['B8'],\n",
        "    c=colors,\n",
        "    s=15  # point size (optional)\n",
        ")\n",
        "\n",
        "# Label the axes\n",
        "ax.set_xlabel('Blue Band (B2)', labelpad=15)\n",
        "ax.set_ylabel('Red Band (B4)', labelpad=15)\n",
        "ax.set_zlabel('NIR Band (B8)', labelpad=15)\n",
        "\n",
        "# Adjust distance of the \"camera\" to the plot (optional)\n",
        "ax.dist = 11\n",
        "\n",
        "# (Optional) Adjust the viewing angle for better orientation\n",
        "# ax.view_init(elev=20, azim=30)  # e.g., 20° above, 30° rotation\n",
        "\n",
        "# Create a custom legend\n",
        "legend_elements = [\n",
        "    Patch(facecolor=Palette[i], edgecolor='k', label=f'Class {Classes[i]}')\n",
        "    for i in range(len(Classes))\n",
        "]\n",
        "ax.legend(\n",
        "    handles=legend_elements,\n",
        "    title=\"Classes\",\n",
        "    loc='upper left',\n",
        "    bbox_to_anchor=(1.05, 1)  # move legend outside the plot if you want\n",
        ")\n",
        "\n",
        "# Add a title\n",
        "plt.title('3D Scatter Plot of Blue, Red, and NIR Bands', pad=20)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EOO6UOgkKTg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create t-distributed Stochastic Neighbor (t-SNE)\n",
        "We will create a t-SNE plot, a popular technique for dimensionality reduction that is especially useful to visualize high-dimensional data in a lower-dimensional (2D or 3D) space.\n",
        "\n",
        "To create a t-SNE plot, first import the necessary libraries, including TSNE from sklearn.manifold. Next, prepare your feature matrix (X) and labels (y): X should be a two-dimensional array with shape [n_samples,n_features][n_samples,n_features], and y should contain the corresponding class labels. When initializing t-SNE, specify parameters such as n_components=2 for a 2D projection, adjust perplexity (commonly in the range of 5 to 50) to balance local and global relationships in the data, and set n_iter to control how many iterations are performed during the embedding process. After calling tsne.fit_transform(X), you will get the 2D embedding, which you can plot by assigning each point’s x- and y-coordinates from X_tsne and coloring them according to their label. Finally, customize the plot by adjusting the size of markers, transparency, labels, titles, and legends to suit your visualization preferences."
      ],
      "metadata": {
        "id": "6_FBpVSp8uxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TSNE\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# 1. Initialize the t-SNE model\n",
        "tsne = TSNE(\n",
        "    n_components=2,  # Project down to 2D\n",
        "    perplexity=30,   # Typical range is 5-50; tune as needed\n",
        "    random_state=42, # For reproducibility\n",
        "    n_iter=1000      # Number of gradient descent iterations\n",
        ")\n",
        "\n",
        "# 2. Fit and transform your feature matrix\n",
        "X_tsne = tsne.fit_transform(X)\n",
        "\n",
        "# 3. Plot the results\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# color_map = {class_label: Palette[i] for i, class_label in enumerate(Classes)}\n",
        "colors = [color_map[label] for label in y]\n",
        "\n",
        "plt.scatter(\n",
        "    X_tsne[:, 0],  # t-SNE x-coordinates\n",
        "    X_tsne[:, 1],  # t-SNE y-coordinates\n",
        "    c=colors,\n",
        "    s=10,          # Marker size\n",
        "    alpha=0.7      # Transparency\n",
        ")\n",
        "\n",
        "plt.title(\"t-SNE Projection of Land Cover Samples\")\n",
        "plt.xlabel(\"t-SNE Dimension 1\")\n",
        "plt.ylabel(\"t-SNE Dimension 2\")\n",
        "\n",
        "# (Optional) Add a legend\n",
        "# If you have a legend, you can manually create it or use existing patches\n",
        "# or you can skip the legend if it becomes cluttered in high-dimensional data\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Toexzdk6jFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create box plots\n",
        "Next, we create box plots for all training data bands, grouped by land cover class."
      ],
      "metadata": {
        "id": "ViBGIbAL-2xX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Melt the DataFrame into a \"long\" format for box plotting\n",
        "df_melt = df_train.melt(\n",
        "    id_vars='class',               # Keep 'class' as an identifier\n",
        "    value_vars=Bands,              # The band columns to melt\n",
        "    var_name='Band',               # Name for the new \"band\" column\n",
        "    value_name='Reflectance'       # Name for the new \"reflectance\" column\n",
        ")\n",
        "\n",
        "# 2. Create a box plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(\n",
        "    x='Band',\n",
        "    y='Reflectance',\n",
        "    hue='class',\n",
        "    data=df_melt,\n",
        "    palette=Palette                # (Optional) use the predefined color palette\n",
        ")\n",
        "\n",
        "# 3. Customize the plot\n",
        "plt.title(\"Box Plots of Reflectance Values by Band and Class\")\n",
        "plt.xlabel(\"Spectral Band\")\n",
        "plt.ylabel(\"Reflectance Value\")\n",
        "plt.legend(title=\"Class\", loc=\"upper right\")\n",
        "\n",
        "# 4. Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xVMzxv1n--UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate Multiple Classifiers\n",
        "\n",
        "We will train four classifiers: K-nearest neighbors (KNN), support vector machine (SVM), decision tree, and random forest. Then we will compare their performance using accuracy, confusion matrices, and classification reports."
      ],
      "metadata": {
        "id": "X-8ljFQc-x2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "knn_preds = knn.predict(X_test)\n",
        "\n",
        "# 2) SVM\n",
        "svm = SVC(kernel='rbf', C=1)\n",
        "svm.fit(X_train, y_train)\n",
        "svm_preds = svm.predict(X_test)\n",
        "\n",
        "# 3) Decision Tree\n",
        "dt = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_preds = dt.predict(X_test)\n",
        "\n",
        "# 4) Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_preds = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "ftWuB56n-ySm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model validation\n",
        "We will compare their performance using accuracy, confusion matrices, and classification reports."
      ],
      "metadata": {
        "id": "LSEEsDM_CyJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate each model\n",
        "models = {\n",
        "    \"KNN\": knn_preds,\n",
        "    \"SVM\": svm_preds,\n",
        "    \"Decision Tree\": dt_preds,\n",
        "    \"Random Forest\": rf_preds\n",
        "}\n",
        "\n",
        "for name, preds in models.items():\n",
        "    print(f\"\\n** {name} **\")\n",
        "    print(\"Accuracy:\", (preds == y_test).mean())\n",
        "\n",
        "    # Classification Report\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, preds, labels=Classes)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Classes)\n",
        "    disp.plot(cmap='Blues')\n",
        "    plt.title(f\"{name} - Confusion Matrix\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7h4sLGwuC0Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Land Cover Classification\n",
        "\n",
        "Choose one or more of the trained classifiers (e.g., Random Forest for demonstration) to predict class labels for every pixel of the Sentinel-2 image.\n",
        "\n",
        "### i. Read the full image stack"
      ],
      "metadata": {
        "id": "IFpqICff_ak-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read all bands as a NumPy array\n",
        "# shape = (band_count, height, width)\n",
        "img_array = image.read()\n",
        "\n",
        "# For example, if the image bands match the ordering of 'Bands' exactly,\n",
        "# index them accordingly. Make sure the array order aligns with your CSV.\n",
        "print(\"Image array shape:\", img_array.shape)  # Should be (#bands, height, width)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQZJAqiN_hXY",
        "outputId": "093ef139-111d-4eaf-c026-376c84b43d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image array shape: (9, 4469, 5317)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ii. Reshape for prediction\n",
        "Scikit-Learn expects a 2D array for prediction, where each row corresponds to a pixel and each column corresponds to a band. Therefore, we need to reshape from (bands, height, width) to (height*width, bands) for input into Scikit-Learn."
      ],
      "metadata": {
        "id": "AlL8ULA-_luW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose and reshape to [#pixels, #bands]\n",
        "# If img_array is [bands, rows, cols]:\n",
        "img_reshaped = img_array.reshape(band_count, -1).T  # shape => (rows*cols, bands)\n",
        "print(\"Reshaped array for prediction:\", img_reshaped.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPlHdUXoALMd",
        "outputId": "358e3997-404b-4254-e36d-76b3ddea9f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped array for prediction: (23761673, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "iii.  Predict and reshape back\n",
        "Use the random forest for prediction and reshape the presiction back."
      ],
      "metadata": {
        "id": "uyBBaiuWAOHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Random Forest as an example\n",
        "prediction = rf.predict(img_reshaped)\n",
        "\n",
        "# Change to an appropriate data type\n",
        "prediction = prediction.astype(np.uint8)\n",
        "\n",
        "# Reshape the prediction back to [height, width]\n",
        "prediction_map = prediction.reshape(height, width)\n",
        "print(\"Predicted map shape:\", prediction_map.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvDw97oDAYwJ",
        "outputId": "1ceaad49-1545-492e-a52f-7434a2bb858f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted map shape: (4469, 5317)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the land cover map\n",
        "\n",
        "Next, visualize the resulting map with a color palette corresponding to each class ID."
      ],
      "metadata": {
        "id": "vxzKWUBiAcDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a discrete colormap\n",
        "# We need one more level than classes for from_levels_and_colors\n",
        "levels = Classes + [max(Classes) + 1]\n",
        "cmap, norm = from_levels_and_colors(levels, Palette)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "im = plt.imshow(prediction_map, cmap=cmap, norm=norm)\n",
        "plt.title(\"Land Cover Map\")\n",
        "\n",
        "# Create colorbar with a shrink factor (0.7 = 70% of default height)\n",
        "cbar = plt.colorbar(im, shrink=0.7)\n",
        "\n",
        "# Center tick labels\n",
        "tick_positions = [i + 0.5 for i in Classes]\n",
        "cbar.set_ticks(tick_positions)\n",
        "cbar.set_ticklabels(Names)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yLT-BbhQAkzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export the Land Cover Map\n",
        "We can save the land cover map to a new GeoTIFF using rasterio."
      ],
      "metadata": {
        "id": "Aft_fLsTAoUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the land cover map\n",
        "output_path = '/content/drive/MyDrive/Bulawayo_Dataset_2024/Bul_RF_LC_2024.tif'\n",
        "with rasterio.open(\n",
        "    output_path,\n",
        "    'w',\n",
        "    driver='GTiff',\n",
        "    height=height,\n",
        "    width=width,\n",
        "    count=1,              # single band\n",
        "    dtype=prediction_map.dtype,\n",
        "    crs=crs,\n",
        "    transform=transform\n",
        ") as dst:\n",
        "    dst.write(prediction_map, 1)\n",
        "\n",
        "print(\"Classification result exported to:\", output_path)"
      ],
      "metadata": {
        "id": "EZBspLVSAvZE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}